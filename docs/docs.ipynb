{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Data Analytics Virtual Internship July 2023\"\n",
        "author: Anshika Jain\n",
        "---"
      ],
      "id": "a6880f84"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quarto\n",
        "\n",
        "## EDA"
      ],
      "id": "d38e2ae5"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Setup\n",
        "jupyter: python3\n",
        "---"
      ],
      "id": "8271dec2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.utils import preprocess_data\n",
        "from src.utils import feature_engg\n",
        "\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, Polygon\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "ROOT_DIR = os.environ.get(\"ROOT_DIR\")\n",
        "os.chdir(ROOT_DIR)"
      ],
      "id": "0c59ffd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Ingestion"
      ],
      "id": "ef08b96e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(r\"data\\raw\\Train.csv\")"
      ],
      "id": "cada0cc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "### Analysing the data\n",
        "\n",
        "Checking the data type and the null values in our data."
      ],
      "id": "80c040e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.info()"
      ],
      "id": "5e049c06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.describe()"
      ],
      "id": "0b58f295",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.isnull().sum()"
      ],
      "id": "579b7cab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking unique values of balcony, total square feet, and size, for understanding what needs to be cleaned and analyse how to clean it."
      ],
      "id": "10b47fab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "columns = ['area_type','balcony', 'total_sqft', 'size']\n",
        "\n",
        "for col in columns:\n",
        "    unique_values = df[col].unique()\n",
        "    print(f\"Unique values for column '{col}': {unique_values}\")"
      ],
      "id": "ee46f458",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checking frequency of variables which have null values\n",
        "\n",
        "This will show us which variables/variable ranges are more prominent in the market"
      ],
      "id": "21431e65"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def size_plot(df,col):\n",
        "    plt.figure(figsize=(30,5))\n",
        "    sns.countplot(df, x=col)\n",
        "    plt.title('Number of houses by size')\n",
        "\n",
        "size_plot(df, 'size')"
      ],
      "id": "11a6f585",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see from the graph that most houses are 2BHK and 3BHK, but there are houses with 2/3 bed and bath mentioned as bedroom only so we will have to clean the data based on that and check again.\n",
        "\n",
        "Spatial analysis using geopandas and geoplots to check location concentration "
      ],
      "id": "753bf32e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def bath_plot():\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.countplot(x=df.bath)\n",
        "    plt.title('Number of Houses by bath count')\n",
        "\n",
        "bath_plot()"
      ],
      "id": "6f7dc296",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bath count of 2 and 3 is most popular, with a few houses with 40 bathrooms!"
      ],
      "id": "14dd453c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def balcony_plot():\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.countplot(x=df.balcony)\n",
        "    plt.title('Number of Houses by balcony count')\n",
        "\n",
        "balcony_plot()"
      ],
      "id": "28ce974e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating plots for other variables to check for other value range and count "
      ],
      "id": "ed31bf8f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def areatype_plot():\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.countplot(x=df.area_type)\n",
        "    plt.title('Area type with count of houses')\n",
        "\n",
        "areatype_plot()"
      ],
      "id": "e1ac46f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def availability_plot():\n",
        "    plt.figure(figsize=(70,10))\n",
        "    sns.countplot(x=df.availability)\n",
        "    plt.title('House Availability')\n",
        "\n",
        "availability_plot()"
      ],
      "id": "3a9fb17b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this graph we see that max houses are offered as ready to move in, and the data is skewed to ready to move in houses."
      ],
      "id": "9df71c5a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def sqft_plot():\n",
        "    plt.figure(figsize=(50,6))\n",
        "    sns.histplot(x=df.total_sqft, binwidth=5000)\n",
        "    plt.title('Max houses for area(sq ft) range')\n",
        "\n",
        "sqft_plot()"
      ],
      "id": "32da7a22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The total area in sq ft is also highly skewed we will have to clean it.\n",
        "We also saw from the unique values that all values in this column weren't consistent, so will have to change that as well."
      ],
      "id": "0191b723"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def price_plot():\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.histplot(x=df.price, binwidth=100)\n",
        "    plt.title('Max houses price range')\n",
        "\n",
        "price_plot()"
      ],
      "id": "6e8622a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the price data is highly skewed, so we will have to remove the skewedness.\n",
        "\n",
        "## Data Cleaning\n",
        "\n",
        "Making a copy of our datframe to work on it"
      ],
      "id": "1ff711e5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "copy_df = df[['area_type', 'availability', 'location', 'size', 'society', 'total_sqft', 'bath', \n",
        "              'balcony', 'price']].copy()"
      ],
      "id": "99f54c57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To clean our data we have:\n",
        "- Removed the words bedroom, bhk and rk from the size column as we saw from above that we need to do that and then created chart for better understanding of the values now.\n",
        "- Removed the null values in the data using mean, median, or a particular value, based on initial analysis.\n",
        "- Some values in the total_sqft column are in the form of x-y so to use those columns I have found the mean of these values x+y/2 and replaced the x-y with this mean.\n",
        "- Certain values in the total_sqft column are not in sqft so to make that an easy transition I have made a dictionary containing some of the metrics\n",
        "- After the data dictionary has been formed we create a function to extract the numeric values from our dataframe copy_df.\n",
        "- Using the functions created we change all the values to sqft \n",
        "- Converting the total area in sqft given as str to numeric format\n",
        "- Removed skewdness of the data \n",
        "\n",
        "Combining the above under one function only so as to be able to use the function for preprocessing the test file as well"
      ],
      "id": "5084af7c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "copy_df = preprocess_data(copy_df)"
      ],
      "id": "3e1146ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "copy_df.isnull().sum()"
      ],
      "id": "dd625706",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the size plot after removing words like bhk, rk and bedrooms"
      ],
      "id": "89e35b55"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "size_plot(copy_df, 'size')"
      ],
      "id": "7357b12f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the price plot after the removed skewness"
      ],
      "id": "5edf148d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def price_plot():\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.histplot(x=copy_df.price, binwidth=0.5)\n",
        "    plt.title('Max houses price range')\n",
        "\n",
        "price_plot()"
      ],
      "id": "cdaefc6b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "\n",
        "- Making a new column month, this column will contain only the months and not the exact date as from graphs plotted we could see that we do not need the data along with the dates\n",
        "- Making a new column ready, this column will contain only the values like ready to move and immediate possession and nothing else as from graphs plotted we could see that we do not need the data along with the too many dates\n",
        "- Combining the two columns month and ready we finally get the column that was desired and we can now plot our graphs based on these columns "
      ],
      "id": "cc4ac471"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "copy_df = feature_engg(copy_df)"
      ],
      "id": "5db459d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a new column address in the copy_df dataframe to map our locations to their longitude and latitudes for geo spatial analysis"
      ],
      "id": "ec232fd8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "copy_df['address'] = copy_df['location']+',Bangalore,Karnataka,India'"
      ],
      "id": "10426614",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Plots with Target Variable(Price)\n",
        "\n",
        "These plots will help determine which variable affects our target variable the most, so that we can move forward with that data.\n",
        "\n",
        "Boxplot for area type and price dependency"
      ],
      "id": "788beb05"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.boxplot(x = copy_df['area_type'], y=copy_df['price'])\n",
        "plt.title('Area Type vs Price')"
      ],
      "id": "5e6e7f0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bocplot for availability and price dependency"
      ],
      "id": "eeb1edff"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "sns.boxplot(x = copy_df['availability'], y=copy_df['price'])\n",
        "plt.title('Availability vs Price')"
      ],
      "id": "cb8b7b5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that this data can be divided into months and then checked with the target variable, otherwise the results of the graph are not clear."
      ],
      "id": "b861f539"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(17,5))\n",
        "sns.boxplot(x = copy_df['extract'], y=copy_df['price'])\n",
        "plt.title('Availability vs Price')"
      ],
      "id": "52b314d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(17,5))\n",
        "month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May','Jun','Jul','Aug','Sep','Oct','Nov', 'Dec']\n",
        "sns.boxplot(x = copy_df['month'], y=copy_df['price'], order= month_order)\n",
        "plt.title('Availability on the basis of months vs Price')"
      ],
      "id": "d23fb368",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(17,5))\n",
        "sns.boxplot(x = copy_df['ready'], y=copy_df['price'])\n",
        "plt.title('Availability on the basis on readiness vs Price')"
      ],
      "id": "e6cc28d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Boxplot for size and price dependency"
      ],
      "id": "2eca180c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.boxplot(x = copy_df['size'], y=copy_df['price'])\n",
        "plt.title('Size vs Price')"
      ],
      "id": "0229728d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Boxplot for location and price dependency "
      ],
      "id": "e32000dc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(40,6))\n",
        "sns.boxplot(x = copy_df['location'], y=copy_df['price'])\n",
        "plt.title('Location vs Price')"
      ],
      "id": "2a4d0dfb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scatterplot for total area in square ft and price dependency"
      ],
      "id": "6814c4f9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.scatterplot(x = copy_df['total_sqft'], y=copy_df['price'])\n",
        "plt.title('Total area in sqft vs Price')"
      ],
      "id": "19a92745",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Boxplot for bath and price dependency "
      ],
      "id": "4487b993"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "sns.boxplot(x = copy_df['bath'], y=copy_df['price'])\n",
        "plt.title('Bath vs Price')"
      ],
      "id": "b7fea739",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Boxplot for balcony and price dependency "
      ],
      "id": "0d67c45e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.boxplot(x = copy_df['balcony'], y=copy_df['price'])\n",
        "plt.title('Balcony vs Price')"
      ],
      "id": "9603f93c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking correlation between bath, balcony and total area to see if any of these is highly correlated and has to ignored."
      ],
      "id": "26d2c0a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "corr_df = copy_df[['bath', 'balcony', 'total_sqft','size', 'price']]\n",
        "correlation_matrix = corr_df.corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='Blues', fmt='.1f')"
      ],
      "id": "cc68b8c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that size and bath are highly correlated and hence one of these based on their correlation with our target variable price can be dropped.\n",
        "\n",
        "Extracting our cleaned data to a file to start modelling on it."
      ],
      "id": "27c3ee89"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "file_path = r'D:\\source\\repos\\OrionDataAnalyticsInternshipJul23-Proj2\\data\\processed/'\n",
        "file_name = \"cleaned.csv\"\n",
        "extract_info = file_path + file_name\n",
        "copy_df.to_csv(extract_info, index=False)"
      ],
      "id": "0f78367c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Geo Spatial Analysis\n",
        "\n",
        "Extracting a new file from copy_df to use for geoencoding"
      ],
      "id": "cfdf6a66"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "address_df = copy_df['address'].drop_duplicates()\n",
        "file_path = r'D:\\source\\repos\\OrionDataAnalyticsInternshipJul23-Proj2\\data\\raw/'\n",
        "file_name = \"address.csv\"\n",
        "extract_info = file_path + file_name\n",
        "address_df.to_csv(extract_info, index=False)"
      ],
      "id": "69308b3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Ingestion: the shapefile to display the map of Bangalore"
      ],
      "id": "a9f4bc3c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bangaloremap = gpd.read_file(r'data\\raw\\bbmpwards\\bbmpwards.shp')"
      ],
      "id": "4448e959",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  Plotting complete Bangalore map using the shapefile"
      ],
      "id": "481e8ea4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bangaloremap.plot(alpha=0.5, edgecolor='k', legend=True)"
      ],
      "id": "75c37901",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Ingestion: the encoded address file"
      ],
      "id": "6b8d1cd0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "encoded_df = pd.read_csv(r\"data\\final\\encoded_addr.csv\")"
      ],
      "id": "2ecc0304",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reformatting our data into a GeoPandas Dataframe because we cannot use it directly as a dataframe"
      ],
      "id": "94699632"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "crs = {'init':'EPSG:4326'}\n",
        "geometry = [Point(xy) for xy in zip(encoded_df['longitude'], encoded_df['latitude'])]\n",
        "geo_df = gpd.GeoDataFrame(encoded_df, crs = crs, geometry = geometry)"
      ],
      "id": "b1175bd2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting our encoded data using subplots on the bangalore map to see if we can come to any conclusion using it"
      ],
      "id": "d37626c4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize = (8,8))\n",
        "bangaloremap.plot(ax=ax, color='lightgrey',edgecolor='Darkgrey')\n",
        "geo_df.plot(ax=ax)\n",
        "\n",
        "ax.set_title('Bangalore Real Estate')\n",
        "ax.set_ylim(12.8, 13.15)\n",
        "ax.set_xlim(77.45,77.8)"
      ],
      "id": "0f0b2ba0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reducing alpha to see where the houses are concentrated, as with all the dots with same intensity it is becoming difficult to do the same."
      ],
      "id": "dcbd8707"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize = (10,10))\n",
        "bangaloremap.to_crs(epsg=4326).plot(ax=ax, color='lightgrey',edgecolor='Darkgrey')\n",
        "geo_df.plot(ax=ax, alpha = .1 )\n",
        "ax.set_title('Bangalore Real Estate')\n",
        "ax.set_ylim(12.8, 13.15)\n",
        "ax.set_xlim(77.45,77.8)\n",
        "# plt.savefig('Property Map')"
      ],
      "id": "4b1afbb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using heatmap to check where the houses with the max price are located, as colours in the heatmap will indicate price range."
      ],
      "id": "b73d1df0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "geo_df['price'] = copy_df['price']\n",
        "fig, ax = plt.subplots(figsize = (10,10))\n",
        "bangaloremap.to_crs(epsg=4326).plot(ax=ax, color='lightgrey',edgecolor='Darkgrey')\n",
        "geo_df.plot(column = 'price', ax=ax, cmap = 'rainbow',\n",
        "            legend = True, legend_kwds={'shrink': 0.3}, \n",
        "            markersize = 10)\n",
        "ax.set_title('Bangalore Price Heatmap')\n",
        "ax.set_ylim(12.80, 13.15)\n",
        "ax.set_xlim(77.45,77.8)"
      ],
      "id": "01cf1b35",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using heatmap to check where the houses with the max area are located, as colours in the heatmap will indicate area range."
      ],
      "id": "e9402e7c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "geo_df['price'] = (copy_df['total_sqft'])\n",
        "fig, ax = plt.subplots(figsize = (10,10))\n",
        "bangaloremap.to_crs(epsg=4326).plot(ax=ax, color='lightgrey',edgecolor='Darkgrey')\n",
        "geo_df.plot(column = 'price', ax=ax, cmap = 'rainbow',\n",
        "            legend = True, legend_kwds={'shrink': 0.3}, \n",
        "            markersize = 10)\n",
        "ax.set_title('Bangalore House Size Heatmap')\n",
        "ax.set_ylim(12.80, 13.15)\n",
        "ax.set_xlim(77.45,77.8)"
      ],
      "id": "60023f75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We can see from geo spatial analysis that there is not particular area in the data that has a concentration of houses, nor an area where house price or house area is always higher. \n",
        "- We can also see that there are many outliers in the data, or it could also suggest that our shapefile is not up to date, or our coordinates are not accurate.\n",
        "- Our data suggests that the location in bangalore doesn't have an affect on price and we do not need it to be able to effectively train our model.\n",
        "\n",
        "Using a correlation matrix to verify the above analysis"
      ],
      "id": "d37b74d0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "geo_df.drop('price',axis=1,inplace = True)\n",
        "new_df = pd.merge(copy_df,geo_df, on='address')\n",
        "\n",
        "corr_df = new_df[['bath', 'balcony', 'total_sqft','size','longitude','latitude', 'price']]\n",
        "correlation_matrix = corr_df.corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='Blues', fmt='.1f')"
      ],
      "id": "0c09bb1e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The correlation matrix proves that our analysis that the locations are not correlated with our target variable and do not need to be used during training our model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Geo Encoding"
      ],
      "id": "4daf2450"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Setup\n",
        "jupyter: python3\n",
        "---"
      ],
      "id": "06f0a2ab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mapbox import Geocoder\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "from dataclasses import dataclass,  fields, _MISSING_TYPE\n",
        "import requests\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "ROOT_DIR = os.environ.get(\"ROOT_DIR\")\n",
        "os.chdir(ROOT_DIR)"
      ],
      "id": "b3a77f00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Ingestion"
      ],
      "id": "7bc34ed7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "address_df = pd.read_csv(r\"data\\raw\\address.csv\")"
      ],
      "id": "d7e5a295",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Mapbox geocoding api\n",
        "\n",
        "Trying for one address only"
      ],
      "id": "9614b35d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "load_dotenv()\n",
        "API_KEY = os.getenv('API_KEY')\n",
        "geocoder = Geocoder(access_token= API_KEY)\n",
        "\n",
        "address_geocodes  = []\n",
        "address = address_df[\"address\"][0]\n",
        "print(f\"Address in my data: {address}\\n----------\")\n",
        "\n",
        "response = geocoder.forward(address).json()\n",
        "print(f\"Response received: \\n\")\n",
        "pprint(response)\n",
        "print(f\"\\n--------\")\n",
        "\n",
        "address_geocode = {'address': address,\n",
        "'place_name': response[\"features\"][0][\"place_name\"],\n",
        "    'relevance': response[\"features\"][0][\"relevance\"],\n",
        "    'bbox': response[\"features\"][0][\"bbox\"],\n",
        "    'longitude': response[\"features\"][0][\"center\"][0],\n",
        "    'lattitude': response[\"features\"][0][\"center\"][1]\n",
        "\n",
        "    }\n",
        "address_geocodes.append(address_geocode)\n",
        "\n",
        "print(f\"keeping the essential values, we get,\")\n",
        "pprint(address_geocode)\n",
        "pprint(address_geocodes)\n",
        "\n",
        "df = pd.DataFrame(address_geocodes)\n",
        "\n",
        "print(df)"
      ],
      "id": "347dd527",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Geoencoding all the addresses"
      ],
      "id": "51bc2c11"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "load_dotenv()\n",
        "API_KEY = os.getenv('API_KEY')\n",
        "geocoder = Geocoder(access_token= API_KEY)\n",
        "\n",
        "address_geocodes  = []\n",
        "\n",
        "for address in address_df.address:\n",
        "    response = geocoder.forward(address).json()\n",
        "\n",
        "    address_geocode = {'address': address,\n",
        "    'place_name': response[\"features\"][0][\"place_name\"],\n",
        "        'relevance': response[\"features\"][0][\"relevance\"],\n",
        "        'longitude': response[\"features\"][0][\"center\"][0],\n",
        "        'lattitude': response[\"features\"][0][\"center\"][1]\n",
        "\n",
        "        }\n",
        "    address_geocodes.append(address_geocode)\n",
        "\n",
        "df = pd.DataFrame(address_geocodes)"
      ],
      "id": "ed731150",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking how our dataframe looks like now"
      ],
      "id": "3d757836"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df"
      ],
      "id": "5b26684e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exporting the file containing all the geoencoded data so that we do not have to wait for geoencoding every time"
      ],
      "id": "c8d9b765"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "file_path = r'data\\processed/'\n",
        "file_name = \"addresses_gecoded_by_mapboxAPI.csv\"\n",
        "extract_info = file_path + file_name\n",
        "df.to_csv(extract_info, index=False)"
      ],
      "id": "a40c6d54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EDA on Mapbox geocoded data\n",
        "\n",
        "Data ingestion of the geo-encoded file"
      ],
      "id": "859177dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(r\"data\\processed\\addresses_gecoded_by_mapboxAPI.csv\")"
      ],
      "id": "7498cec1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finding all the rows where latitude and longitude point to the general location of Bangalore only"
      ],
      "id": "0d329995"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inaccurate_df = df.loc[(df['longitude'] == 77.591300) & (df['lattitude'] == 12.979120)]"
      ],
      "id": "e9796a3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting distribution of relevance, longitude and latitude "
      ],
      "id": "706beaf6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.histplot(df.relevance)\n",
        "plt.title(\"Histplot for Relevance\")"
      ],
      "id": "d833625a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.histplot(df.longitude)\n",
        "plt.title(\"Histplot for Longitude\")"
      ],
      "id": "a18bc3c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.histplot(df.lattitude)\n",
        "plt.title(\"Histplot for Lattitude\")"
      ],
      "id": "04acbddd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting longitude and latitude using scatterplot"
      ],
      "id": "7b70ad31"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.scatterplot(x= df.longitude, y=df.lattitude)\n",
        "plt.title('Latitude vs Longitude')\n",
        "plt.ylabel('latitude')"
      ],
      "id": "565d42c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using https://geocode.maps.co/ free api\n",
        "\n",
        "Created a dataclass to skip errors where the api does not have the data for our given address"
      ],
      "id": "49ad0738"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@dataclass\n",
        "class GeocodedAddress:\n",
        "    address: str\n",
        "    place_name: str = 'NOT_FOUND' \n",
        "    relevance: float = 0\n",
        "    longitude: float = None\n",
        "    latitude: float = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        # Loop through the fields\n",
        "        for field in fields(self):\n",
        "            # If there is a default and the value of the field is none we can assign a value\n",
        "            if not isinstance(field.default, _MISSING_TYPE) and getattr(self, field.name) is None:\n",
        "                setattr(self, field.name, field.default)"
      ],
      "id": "ba5a296e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trying for one address only"
      ],
      "id": "1166c567"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "address_geocodes  = []\n",
        "address = address_df[\"address\"][3]\n",
        "print(f\"Address in my data: {address}\\n----------\")\n",
        "\n",
        "geocode_base_url = f\"https://geocode.maps.co/search?q={address}\"\n",
        "response = requests.get(geocode_base_url).json()\n",
        "print(f\"Response received: \\n\")\n",
        "pprint(response)\n",
        "print(f\"\\n--------\")\n",
        "\n",
        "\n",
        "if len(response) >=1:\n",
        "\n",
        "    address_geocode = GeocodedAddress(\n",
        "        address=address,\n",
        "        place_name = response[0][\"display_name\"],\n",
        "        relevance = response[0][\"importance\"],\n",
        "        longitude = response[0][\"lon\"],\n",
        "        latitude = response[0][\"lat\"]\n",
        "    )\n",
        "else: \n",
        "    address_geocode = GeocodedAddress(\n",
        "        address=address\n",
        "    )\n",
        "\n",
        "    address_geocodes.append(address_geocode.__dict__)\n",
        "\n",
        "    print(f\"keeping the essential values, we get,\")\n",
        "    pprint(address_geocode)\n",
        "    pprint(address_geocodes)\n",
        "\n",
        "    df = pd.DataFrame(address_geocodes)\n",
        "\n",
        "    print(df)"
      ],
      "id": "15eabfad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Geoencoding for all the addresses"
      ],
      "id": "6d9bdf76"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "address_geocodes  = []\n",
        "\n",
        "for address in address_df.address:\n",
        "    print(address)\n",
        "    geocode_base_url = f\"https://geocode.maps.co/search?q={address}\"\n",
        "    response = requests.get(geocode_base_url).json()\n",
        "\n",
        "    if len(response) >=1:\n",
        "\n",
        "        address_geocode = GeocodedAddress(\n",
        "            address=address,\n",
        "            place_name = response[0][\"display_name\"],\n",
        "            relevance = response[0][\"importance\"],\n",
        "            longitude = response[0][\"lon\"],\n",
        "            latitude = response[0][\"lat\"]\n",
        "        )\n",
        "    else: \n",
        "        address_geocode = GeocodedAddress(\n",
        "            address=address\n",
        "        )\n",
        "\n",
        "    address_geocodes.append(address_geocode.__dict__)\n",
        "\n",
        "\n",
        "geocode_map_df = pd.DataFrame(address_geocodes)"
      ],
      "id": "3c785e13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exporting the file containing all the geoencoded data so that we do not have to wait for geoencoding every time"
      ],
      "id": "3c6be6cc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "file_path = r'data\\processed/'\n",
        "file_name = \"addresses_geocoded_by_geocodemaps.csv\"\n",
        "extract_info = file_path + file_name\n",
        "geocode_map_df.to_csv(extract_info, index=False)"
      ],
      "id": "1912be6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EDA on geocode.map.co geocoded data\n",
        "\n",
        "Data ingestion on the geoencoded file"
      ],
      "id": "2fcb3636"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "geocode_map_df = pd.read_csv(r\"data\\processed\\addresses_geocoded_by_geocodemaps.csv\")"
      ],
      "id": "e7d42c96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking how our dataframe looks like "
      ],
      "id": "c61c7791"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "geocode_map_df"
      ],
      "id": "235fa06c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finding all the rows where place_name is NOT_FOUND"
      ],
      "id": "e34811c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "not_found_df = geocode_map_df.loc[geocode_map_df['place_name'] == 'NOT_FOUND']"
      ],
      "id": "cee2d34c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting distribution of relevance, longitude and latitude"
      ],
      "id": "6398368c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.histplot(geocode_map_df.relevance)\n",
        "plt.title(\"Histplot for Relevance\")"
      ],
      "id": "0dcdeee7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.histplot(geocode_map_df.longitude)\n",
        "plt.title(\"Histplot for Longitude\")"
      ],
      "id": "44812e47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.histplot(geocode_map_df.latitude)\n",
        "plt.title(\"Histplot for Latitude\")"
      ],
      "id": "df3bbc04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting longitude and latitude using scatterplot"
      ],
      "id": "8118fe53"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.scatterplot(x= geocode_map_df.longitude, y=geocode_map_df.latitude)\n",
        "plt.title('Latitude vs Longitude')"
      ],
      "id": "a39b1619",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We used 2 geoencoding APIs mapbox and geocode.maps.co from the analysis above it is clear that the encoding by mapbox is far more efficient than by geocode.map url. We see from the not found columns that the url has 477 addresses not available where as mapbox only had 154.\n",
        "Furthermore with the columns that it did found mapbox has a relevance of 1 with most addresses, which means being able to encode the exact address we want where it is very less in case of the url, which is also showcased while plotting the scatterplot.\n",
        "\n",
        "## Merging the 2 dataframes for better results \n",
        "\n",
        "Extracting only the address from our data with multiple longitude and latitude taken as the general bangalore coordinates"
      ],
      "id": "5d173dc4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "addr_inaccurate_df = inaccurate_df['address']"
      ],
      "id": "d6947070",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merged the address column with the geocode url encoded data to get accurate coordinates in place of the general coordinates"
      ],
      "id": "cd272db9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "merged_df = pd.merge(addr_inaccurate_df,geocode_map_df)"
      ],
      "id": "5230623f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking how many of them are found and creating a dataframe for it"
      ],
      "id": "ef37b559"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "found_df = merged_df.loc[merged_df['place_name']!='NOT_FOUND']\n",
        "found_df.shape[0]"
      ],
      "id": "ba7cd253",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that 54 rows now have better coordinates than the general bangalore coordinates, and we now move on to put them in our original df "
      ],
      "id": "f252d154"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set the index of found_df to be the address column\n",
        "found_df.set_index('address', inplace=True)\n",
        "\n",
        "# Iterate through the rows of df and update the longitude and latitude values\n",
        "for index, row in df.iterrows():\n",
        "    address = row['address']\n",
        "    if address in found_df.index:\n",
        "        df.at[index, 'place_name'] = found_df.at[address, 'place_name']\n",
        "        df.at[index, 'longitude'] = found_df.at[address, 'longitude']\n",
        "        df.at[index, 'lattitude'] = found_df.at[address, 'latitude']\n",
        "\n",
        "# Reset the index to bring the DataFrame back to its original format\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "id": "72ad0f14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conducting Sanity Checks"
      ],
      "id": "15adae5a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df"
      ],
      "id": "52d30857",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.loc[(df['longitude'] == 77.591300) & (df['lattitude'] == 12.979120)]"
      ],
      "id": "b4690b3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final geoencoded data "
      ],
      "id": "35cd1496"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.scatterplot(x= df.longitude, y=df.lattitude)\n",
        "plt.title('Latitude vs Longitude')\n",
        "plt.ylabel('latitude')"
      ],
      "id": "f5bda47e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extracting this dataframe now as it is better than our original encoded datasets."
      ],
      "id": "2524935e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "file_path = r'data\\final/'\n",
        "file_name = \"encoded_addr.csv\"\n",
        "extract_info = file_path + file_name\n",
        "geocode_map_df.to_csv(extract_info, index=False)"
      ],
      "id": "a2dac3f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelling "
      ],
      "id": "c36b5dd8"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Setup\n",
        "jupyter: python3\n",
        "---"
      ],
      "id": "2197e8b3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score  \n",
        "import joblib\n",
        "import os \n",
        "\n",
        "from src.utils import preprocess_data\n",
        "from src.utils import feature_engg"
      ],
      "id": "d913e3dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Ingestion"
      ],
      "id": "3eb183fc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_df = pd.read_csv(r\"data\\processed\\cleaned.csv\")"
      ],
      "id": "560fb93e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression Model"
      ],
      "id": "eb3a02df"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X= model_df[['area_type', 'total_sqft', 'bath', 'balcony', 'extract']]\n",
        "Y = model_df['price']\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=50)\n",
        "\n",
        "column_trans = ColumnTransformer(transformers=\n",
        "                                 [('onehot', OneHotEncoder(), ['area_type', 'extract']),\n",
        "                                  ('scaler', StandardScaler(), ['total_sqft', 'bath', 'balcony'])],\n",
        "                                  remainder='passthrough')\n",
        "\n",
        "pipeline = make_pipeline(column_trans, LinearRegression())\n",
        "\n",
        "pipeline.fit(X, Y)\n",
        "\n",
        "# y_pred = pipeline.predict(x_test)\n",
        "\n",
        "filename = os.path.join(\"models\", \"1st_model_LR.joblib\")\n",
        "joblib.dump(pipeline, filename)\n",
        "\n",
        "loaded_model_LR = joblib.load(filename)\n",
        "result = loaded_model_LR.score(X, Y)\n",
        "print(result)"
      ],
      "id": "2fde9d99",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest Regressor Model"
      ],
      "id": "cc66611a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = model_df[['area_type', 'total_sqft', 'bath', 'balcony', 'extract']]\n",
        "Y = model_df['price']\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=50)\n",
        "\n",
        "column_trans = ColumnTransformer(transformers=\n",
        "                                 [('onehot', OneHotEncoder(), ['area_type', 'extract']),\n",
        "                                  ('scaler', StandardScaler(), ['total_sqft', 'bath', 'balcony'])],\n",
        "                                  remainder='passthrough')\n",
        "\n",
        "pipeline = make_pipeline(column_trans, RandomForestRegressor())\n",
        "\n",
        "pipeline.fit(X, Y)\n",
        "\n",
        "# y_pred = pipeline.predict(x_test)\n",
        "\n",
        "filename = os.path.join(\"models\", \"1st_model_RF.joblib\")\n",
        "joblib.dump(pipeline, filename)\n",
        "\n",
        "loaded_model_RF1 = joblib.load(filename)\n",
        "result = loaded_model_RF1.score(X, Y)\n",
        "print(result)"
      ],
      "id": "06cfb497",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking random forest by adding the parameter that was found to be highly correlated during EDA, but we know that since the values in parameter size were very less it is possible that the correlation matrix results are not as accurate."
      ],
      "id": "7c0b2ed1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = model_df[['area_type','size','total_sqft', 'bath', 'balcony', 'extract']]\n",
        "Y = model_df['price']\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=50)\n",
        "\n",
        "column_trans = ColumnTransformer(transformers=\n",
        "                                 [('onehot', OneHotEncoder(), ['area_type', 'extract']),\n",
        "                                  ('scaler', StandardScaler(), ['size','total_sqft', 'bath', 'balcony'])],\n",
        "                                  remainder='passthrough')\n",
        "\n",
        "pipeline = make_pipeline(column_trans, RandomForestRegressor())\n",
        "\n",
        "pipeline.fit(X, Y)\n",
        "\n",
        "# y_pred = pipeline.predict(x_test)\n",
        "\n",
        "filename = os.path.join(\"models\", \"2nd_model_RF.joblib\")\n",
        "joblib.dump(pipeline, filename)\n",
        "\n",
        "loaded_model_RF2 = joblib.load(filename)\n",
        "result = loaded_model_RF2.score(X, Y)\n",
        "print(result)"
      ],
      "id": "d07996b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n",
        "\n",
        "Using the test data to evaluate our models created.\n",
        "- We first read the test file\n",
        "- Then preprocess the test file\n",
        "- Finally we add the new features in the test file"
      ],
      "id": "68bc1c9e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_data = pd.read_csv(r\"data/raw/Test.csv\")\n",
        "clean_test_data = preprocess_data(test_data)\n",
        "clean_test_data = feature_engg(clean_test_data)"
      ],
      "id": "39ec32e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear Regression"
      ],
      "id": "377a86fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_test = clean_test_data[['area_type','total_sqft', 'bath', 'balcony', 'extract']]\n",
        "y_pred = clean_test_data['price']\n",
        "\n",
        "y_pred_lr = loaded_model_LR.predict(x_test)\n",
        "result = loaded_model_LR.score(x_test, y_pred_lr)\n",
        "print(\"R-squared value on test data:\", result)"
      ],
      "id": "84dcb7ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest\n",
        "\n",
        "Using the first random forest model"
      ],
      "id": "59969766"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clean_test_data.head()"
      ],
      "id": "647f1402",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_test = clean_test_data[['area_type','total_sqft', 'bath', 'balcony', 'extract']]\n",
        "y_pred = clean_test_data['price']\n",
        "\n",
        "loaded_model_RF1 = joblib.load(os.path.join(\"models\", \"1st_model_RF.joblib\"))\n",
        "y_pred_rf1 = loaded_model_RF1.predict(x_test)\n",
        "price = np.expm1(y_pred_rf1)\n",
        "\n",
        "# result = loaded_model_RF1.score(x_test, y_pred_rf1)\n",
        "# print(\"R-squared value on test data:\", result)"
      ],
      "id": "5f7b8ac3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "headerList = ['price']\n",
        "pd.DataFrame(price).to_csv(r'data\\final\\submission_RF1.csv',header=headerList, index_label= 'id')"
      ],
      "id": "f2df855d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the second random forest model"
      ],
      "id": "c78978d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_test = clean_test_data[['area_type','size','total_sqft', 'bath', 'balcony', 'extract']]\n",
        "y_pred = clean_test_data['price']\n",
        "\n",
        "y_pred_rf2 = loaded_model_RF2.predict(x_test)\n",
        "price = np.expm1(y_pred_rf2)\n",
        "# result = loaded_model_RF2.score(x_test, y_pred_rf2)\n",
        "# print(\"R-squared value on test data:\", result)"
      ],
      "id": "25de0ab7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "headerList = ['price']\n",
        "pd.DataFrame(price).to_csv(r'data\\final\\submission_RF2.csv',header=headerList, index_label= 'id')"
      ],
      "id": "0c5d81b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Machine hack r score\n",
        "\n",
        "![image.png](attachment:image.png)\n"
      ],
      "id": "80216867"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}